{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bogdanbabych/experiments_NLTK/blob/main/bleuFileV03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "cEvHsd4OnnO2"
      },
      "cell_type": "markdown",
      "source": [
        "## BLEU: BiLingual Evaluation Understudy\n",
        "\n",
        "*NLP evaluation metric used in Machine Translation tasks*\n",
        "\n",
        "*Suitable for measuring corpus level similarity*\n",
        "\n",
        "*$n$-gram comparison between words in candidate sentence and reference sentences*\n",
        "\n",
        "*Range: 0 (no match) to 1 (exact match)*"
      ]
    },
    {
      "metadata": {
        "id": "_arqa6LRnzCL"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Libraries\n",
        "*Install and import necessary libraries*\n"
      ]
    },
    {
      "metadata": {
        "id": "xFOnk5JdnuYQ",
        "outputId": "3cd64561-a91d-400d-a462-5c6719e328fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import nltk.translate.bleu_score as bleu\n",
        "\n",
        "import math\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "try:\n",
        "  nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "  nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SVkfsYSZq_zn"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Dataset\n",
        "*Array of words: candidate and reference sentences split into words*"
      ]
    },
    {
      "metadata": {
        "id": "Dr9v92X0r9VM"
      },
      "cell_type": "code",
      "source": [
        "hyp = str('EU Commission President von der Leyen promises US scientists financial incentives and a legal obligation to respect their freedom of research.').split()\n",
        "hypES = str('In an implicit criticism of Donald Trump\\'s policies, Ursula von der Leyen said that attacking science is a \"gigantic miscalculation.\"').split()\n",
        "hypESdeepL = str('In an implicit criticism against Donald Trump\\'s policies, Ursula von der Leyen said that attacking science is a \"gigantic miscalculation\".').split()\n",
        "\n",
        "ref_a = str('In implicit criticism against Donald Trump\\'s policies, Ursula von der Leyen said attacking free and open science was a \"gigantic miscalculation\".').split()\n",
        "ref_b = str('In a veiled critique of Donald Trump\\'s policies, Ursula von der Leyen stated that undermining free and open science was a \"huge mistake\".').split()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading zip file with MT output (Google)"
      ],
      "metadata": {
        "id": "IcfgVFxOZzZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/b128ec0eb79c436995db/?dl=1\n"
      ],
      "metadata": {
        "id": "AJPhshk7XGxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv index.html?dl=1 euronews2025mtG.zip"
      ],
      "metadata": {
        "id": "ycbaZIYFXh6V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip euronews2025mtG.zip"
      ],
      "metadata": {
        "id": "dN-wO4jRXkFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading zip file with original human references\n",
        "(including English original)"
      ],
      "metadata": {
        "id": "WwQYqtHiZ64Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/0150d4ce490546f8b5fb/?dl=1\n",
        "!mv index.html?dl=1 euronews2025ori.zip\n",
        "!unzip euronews2025ori.zip\n"
      ],
      "metadata": {
        "id": "QdX8HRyUYlj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://heibox.uni-heidelberg.de/f/ed9e7534537c4011b1d6/?dl=1\n",
        "!mv index.html?dl=1 euronews2025mtD.zip\n",
        "!unzip euronews2025mtD.zip\n"
      ],
      "metadata": {
        "id": "z2xWotU62B-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_ref = '/content/euronews2025ori/news01en.txt'\n",
        "\n",
        "with open(file_ref, 'r') as file:\n",
        "    file_content_ref = file.read()\n",
        "\n"
      ],
      "metadata": {
        "id": "bo-s_i_IRpav"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_ref = file_content_ref.split()\n",
        "file_ref"
      ],
      "metadata": {
        "id": "hRhxKK62-YrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_test = '/content/euronews2025mtG/news01de2enG.txt'\n",
        "\n",
        "with open(file_test, 'r') as file:\n",
        "    file_content_test = file.read()"
      ],
      "metadata": {
        "id": "Tpj42aDYpw-B"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_test = file_content_test.split()"
      ],
      "metadata": {
        "id": "17Me9Fbf-ynw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PQYjMHOgsyfT"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. *Sentence* score calculation\n",
        "*Compares 1 hypothesis (candidate or source sentence) with 1+ reference sentences, returning the highest score when compared to multiple reference sentences.*"
      ]
    },
    {
      "metadata": {
        "id": "jXGCD-pi-jt5",
        "outputId": "7721da0d-0534-4228-fab2-4dd241533069",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "score_ref_a = bleu.sentence_bleu([file_ref], file_test)\n",
        "print(\"File Hyp and file ref_a : {}\".format(score_ref_a))\n",
        "# score_ref_b = bleu.sentence_bleu([ref_b], hypES)\n",
        "# print(\"Hyp and ref_b : {}\".format(score_ref_b))\n",
        "# score_ref_ab = bleu.sentence_bleu([ref_a, ref_b], hypES)\n",
        "# print(\"Hyp vs multiple refs: {}\".format(score_ref_ab))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Hyp and file ref_a : 0.49748908893556004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "\n",
        "def get_files_in_directory(directory_path):\n",
        "    file_paths = []\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if re.match(r'.*\\.txt', file_path):\n",
        "                file_paths.append(file_path)\n",
        "    return file_paths\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q9Iw4BFn4xch"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filesGoogle = get_files_in_directory('/content/euronews2025mtG')\n",
        "filesDeepL = get_files_in_directory('/content/euronews2025mtD')"
      ],
      "metadata": {
        "id": "7GAZ1Ox255Eq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in sorted(filesGoogle):\n",
        "    with open(file, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        file_test = file_content.split()\n",
        "        score_ref_a = bleu.sentence_bleu([file_ref], file_test)\n",
        "        print(f'{file.name}\\t{score_ref_a}')\n",
        "        # print(file + '\\t' + str(score_ref_a) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4SnntYa6s0g",
        "outputId": "0178460e-298c-4e23-9ed0-15ea30e91ef3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/euronews2025mtG/news01de2enG.txt\t0.49748908893556004\n",
            "/content/euronews2025mtG/news01es2enG.txt\t0.5642424347906835\n",
            "/content/euronews2025mtG/news01fr2enG.txt\t0.47334922414764874\n",
            "/content/euronews2025mtG/news01gr2enG.txt\t0.5476813541393837\n",
            "/content/euronews2025mtG/news01it2enG.txt\t0.26524741699516213\n",
            "/content/euronews2025mtG/news01pt2enG.txt\t0.5237668255949999\n",
            "/content/euronews2025mtG/news01tr2enG.txt\t0.39399617321274066\n",
            "/content/euronews2025mtG/news01uk2enG.txt\t0.37914140475282493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file in sorted(filesDeepL):\n",
        "    with open(file, 'r') as file:\n",
        "        file_content = file.read()\n",
        "        file_test = file_content.split()\n",
        "        score_ref_a = bleu.sentence_bleu([file_ref], file_test)\n",
        "        print(f'{file.name}\\t{score_ref_a}')\n",
        "        # print(file + '\\t' + str(score_ref_a) + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqw3VsrV8S50",
        "outputId": "14b93dbd-1329-4556-ba2f-72d4a026cdeb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/euronews2025mtD/news01de2enD.txt\t0.44956478865557\n",
            "/content/euronews2025mtD/news01es2enD.txt\t0.5154725452481462\n",
            "/content/euronews2025mtD/news01fr2enD.txt\t0.407912611075686\n",
            "/content/euronews2025mtD/news01gr2enD.txt\t0.533327364755979\n",
            "/content/euronews2025mtD/news01it2enD.txt\t0.259381251414578\n",
            "/content/euronews2025mtD/news01pt2enD.txt\t0.5335449105401048\n",
            "/content/euronews2025mtD/news01tr2enD.txt\t0.3727644435021556\n",
            "/content/euronews2025mtD/news01uk2enD.txt\t0.37407665692498276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgQ9_WkY59Qs",
        "outputId": "009b8f8a-7ebb-4903-a400-7823fb195290"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/euronews2025ori/news01tr.txt',\n",
              " '/content/euronews2025ori/news01de.txt',\n",
              " '/content/euronews2025ori/news01pt.txt',\n",
              " '/content/euronews2025ori/news01en.txt',\n",
              " '/content/euronews2025ori/news01uk.txt',\n",
              " '/content/euronews2025ori/news01es.txt',\n",
              " '/content/euronews2025ori/news01fr.txt',\n",
              " '/content/euronews2025ori/news01it.txt',\n",
              " '/content/euronews2025ori/news01gr.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "NW9ZXSsSs6bE"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. *Corpus* score calculation\n",
        "*Compares 1 candidate document with multiple sentence and 1+ reference documents also with multiple sentences.*\n",
        "\n",
        "* Different than averaging BLEU scores of each sentence, it calculates the score by *\"summing the numerators and denominators for each hypothesis-reference(s) pairs before the division\"*"
      ]
    },
    {
      "metadata": {
        "id": "XATgeqKPP02p",
        "outputId": "c9aa89ba-1cb3-42cd-e599-b42889cf3567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "score_ref_a = bleu.corpus_bleu([[ref_a]], [hyp])\n",
        "print(\"1 document with 1 reference sentence: {}\".format(score_ref_a))\n",
        "score_ref_a = bleu.corpus_bleu([[ref_a, ref_b]], [hyp])\n",
        "print(\"1 document with 2 reference sentences: {}\".format(score_ref_a))\n",
        "score_ref_a = bleu.corpus_bleu([[ref_a], [ref_b]], [hyp, hyp])\n",
        "print(\"2 documents with 1 reference sentence each: {}\".format(score_ref_a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 document with 1 reference sentence: 1.0\n",
            "1 document with 2 reference sentences: 1.0\n",
            "2 documents with 1 reference sentence each: 0.8778107713916036\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "hxgDToMctnTM"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. BLEU-$n$\n",
        "*In BLEU-$n$, $n$-gram scores can be obtained in both **sentence** and **corpus** calculations and they're indicated by the **weights** parameter.*\n",
        "\n",
        "* *weights*: length 4, where each index contains a weight corresponding to its respective $n$-gram.\n",
        "* $n$-gram with $n \\in \\{1, 2, 3, 4\\}$\n",
        "* $\\textit{weights}=(W_{N=1}, W_{N=2}, W_{N=3}, W_{N=4})$\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0J2_E8zQP6K9",
        "outputId": "8644947c-e3ea-4a77-bc63-741d00516f7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "score_1gram = bleu.sentence_bleu([ref_b], hyp, weights=(1,0,0,0))\n",
        "score_2gram = bleu.sentence_bleu([ref_b], hyp, weights=(0,1,0,0))\n",
        "score_3gram = bleu.sentence_bleu([ref_b], hyp, weights=(0,0,1,0))\n",
        "score_4gram = bleu.sentence_bleu([ref_b], hyp, weights=(0,0,0,1))\n",
        "print(\"N-grams: 1-{}, 2-{}, 3-{}, 4-{}\".format(score_1gram, score_2gram, score_3gram, score_4gram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-grams: 1-1.0, 2-0.9, 3-0.6666666666666666, 4-0.5\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "El1PaLtIDQyH"
      },
      "cell_type": "markdown",
      "source": [
        "* Cumulative N-grams: *by default, the score is calculatedby considering all $N$-grams equally in a geometric mean*"
      ]
    },
    {
      "metadata": {
        "id": "ntJ1UkEaP-90",
        "outputId": "679d6b1d-83ed-46a4-f1ef-9d4b417f0494",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "score_ngram1 = bleu.sentence_bleu([ref_b], hyp)\n",
        "score_ngram = bleu.sentence_bleu([ref_b], hyp, weights=(0.25,0.25,0.25,0.25))\n",
        "score_ngram_geo = (11/11*9/10*6/9*4/8)**0.25\n",
        "print(\"N-grams: {} = {} = \".format(score_ngram1, score_ngram, score_ngram_geo))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-grams: 0.7400828044922853 = 0.7400828044922853 = \n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "oq3WktXzV2I9"
      },
      "cell_type": "markdown",
      "source": [
        "### Further testing"
      ]
    },
    {
      "metadata": {
        "id": "rdVRiZQc-ebC",
        "outputId": "61cd9cff-9190-48b8-9e16-5396dbb001d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "hyp = str('she read the book because she was interested in world history').split()\n",
        "ref_a = str('she was interested in world history because she read the book').split()\n",
        "hyp_b = str('the book she read was about modern civilizations.').split()\n",
        "ref_b = str('the book she read was about modern civilizations.').split()\n",
        "\n",
        "score_a = bleu.sentence_bleu([ref_a], hyp)\n",
        "score_b = bleu.sentence_bleu([ref_b], hyp_b)\n",
        "score_ab = bleu.sentence_bleu([ref_a], hyp_b)\n",
        "score_ba = bleu.sentence_bleu([ref_b], hyp)\n",
        "score_ref_a = bleu.corpus_bleu([[ref_a], [ref_b]], [hyp, hyp_b])\n",
        "average = (score_a+score_b)/2\n",
        "corpus = math.pow((11+8)/19 * (9+7)/(17) * (6+6)/(9+6) * (4+5)/(8+5), 1/4)\n",
        "print(\"Sent: {}, {}, {}, {} - Corpus {}, {}, {}\".format(score_a, score_b, score_ab, score_ba, score_ref_a, average, corpus))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sent: 0.7400828044922853, 1.0, 6.664457123729399e-155, 8.190757052088229e-155 - Corpus 0.8496988908521796, 0.8700414022461427, 0.8496988908521795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ]
    }
  ]
}